---
- name: Setup k8s proxy
  hosts: k8proxy
  become: true
  vars:
    conductor_plane_group: k8cdrs
    kube_control_nodes: "{{ hostvars[inventory_hostname]['groups'][conductor_plane_group] }}"
  handlers:
    - name: Restart HAProxy
      ansible.builtin.systemd:
        name: haproxy
        state: restarted
        enabled: true
        daemon_reload: true

  tasks:
    - name: Install haproxy
      ansible.builtin.apt:
        name: haproxy
        state: present

    - name: Copy haproxy config
      ansible.builtin.template:
        src: haproxy.cfg.j2
        dest: /etc/haproxy/haproxy.cfg
        owner: root
        group: root
        mode: "0644"
      notify: Restart HAProxy

    - name: Generate Private Key Certs
      community.crypto.openssl_privatekey:
        path: /etc/ssl/private/kube_certs.key
        mode: "0440"
        owner: root
        group: root
        type: ECC
        curve: secp521r1
      notify: Restart HAProxy

    - name: Copy Openssl Config
      ansible.builtin.template:
        src: server_openssl.conf.j2
        dest: /etc/ssl/certs/kube_certs.conf
        owner: root
        group: root
        mode: "0644"

    - name: Generate Public Key Certs
      ansible.builtin.command:
        cmd: |-
          openssl req
          -x509
          -new
          -sha512
          -nodes
          -key /etc/ssl/private/kube_certs.key
          -config /etc/ssl/certs/kube_certs.conf
          -days 7307
          -out /etc/ssl/certs/kube_certs.crt
        creates: /etc/ssl/certs/kube_certs.crt
      notify: Restart HAProxy

    - name: Configure UFW services
      community.general.ufw:
        rule: allow
        port: "{{ item }}"
        protocol: tcp
        comment: Allow {{ item }} for HAProxy to kubeadm
      with_items:
        - 6443

- name: Install Kubernetes
  hosts:
    - k8cdrs
    - k8wkrs
  tags:
    - install_k8s
  become: true
  handlers:
    - name: Enable noswap service
      ansible.builtin.systemd:
        name: noswap
        state: started
        enabled: true
        daemon_reload: true

    - name: Restart Containerd
      ansible.builtin.systemd:
        name: containerd
        state: restarted
        enabled: true
        daemon_reload: true
  tasks:
    - name: Create Docker group
      ansible.builtin.group:
        name: docker
        state: present
        gid: 520

    - name: Create Docker user
      ansible.builtin.user:
        name: docker
        group: docker
        uid: 520
        state: present

    - name: Add Ansible to docker
      ansible.builtin.user:
        name: Ansible
        groups: docker
        append: true

    - name: Add conf for containerd
      ansible.builtin.blockinfile:
        path: /etc/modules-load.d/containerd.conf
        mode: "0640"
        group: docker
        owner: root
        create: true
        block: |
          overlay
          br_netfilter

    - name: Install Overlay and netfilter moduels
      community.general.modprobe:
        name: "{{ item }}"
        state: present
      with_items:
        - overlay
        - br_netfilter

    - name: Add sysctl conf for containerd
      ansible.posix.sysctl:
        sysctl_file: /etc/sysctl.d/99-kubernetes-cri.conf
        state: present
        name: "{{ item }}"
        reload: true
        value: "1"
      with_items:
        - net.bridge.bridge-nf-call-iptables
        - net.ipv4.ip_forward
        - net.bridge.bridge-nf-call-ip6tables

    - name: Add docker gpg key
      ansible.builtin.apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add Kubernetes apt key
      ansible.builtin.apt_key:
        url: https://packages.cloud.google.com/apt/doc/apt-key.gpg

    - name: Add docker repository
      ansible.builtin.apt_repository:
        repo: |-
          deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable
        state: present

    - name: Add Kubernetes repository
      ansible.builtin.apt_repository:
        repo: deb https://apt.kubernetes.io/ kubernetes-xenial main
        state: present

    - name: Write noswap systemd service config file
      ansible.builtin.template:
        src: noswap.service.j2
        dest: /etc/systemd/system/noswap.service
        owner: root
        group: root
        mode: "0644"
      notify: Enable noswap service

    - name: Install docker and kube packages
      ansible.builtin.apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - kubelet
          - kubecolor
          - kubeadm
          - kubectl
          - apt-transport-https
        state: present

    - name: Enable docker and kube
      ansible.builtin.systemd:
        name: "{{ item }}"
        state: started
        enabled: true
      with_items:
        - docker
        - kubelet
        - containerd

    - name: Copy containerd config
      ansible.builtin.copy:
        src: containerd.toml
        dest: /etc/containerd/config.toml
        mode: "0644"
        owner: root
        group: root
      notify: Restart Containerd

- name: Open Firewall on the control plane
  hosts: k8cdrs
  become: true
  tasks:
    - name: Open Control Plane Ports
      community.general.ufw:
        rule: allow
        port: "{{ item }}"
        protocol: tcp
        comment: Allow {{ item }} kubeadm
      with_items:
        - 6443
        - 10250
        - 10259
        - 10257
        - 2379
        - 2380
        - 2381

- name: Open Firewall on the worker nodes
  hosts: k8wkrs
  become: true
  tasks:
    - name: Open Worker node Plane Kublet Port
      community.general.ufw:
        rule: allow
        port: "10250"
        protocol: tcp
        comment: Allow 10250 Kublet Port
    - name: Open Worker node Plane NodePort Services
      community.general.ufw:
        rule: allow
        port: 30000:32767
        protocol: tcp
        comment: Allow 30000:32767 NodePort Services

- name: Initialize the first Control Plane
  tags:
    - control_init
  become: true
  hosts: k8cdrs[0]
  strategy: linear
  vars:
    kube_network_real: "{{ kube_network | default('10.32.0.0/12') }}"
    kube_service_network_real: "{{ kube_service_network | default('10.96.0.0/16') }}"
  handlers:
    - name: Restart HAProxy
      delegate_to: "{{ groups['k8proxy'][0] }}"
      ansible.builtin.systemd:
        name: haproxy
        state: restarted
        enabled: true
        daemon_reload: true
  tasks:
    - name: Check kube cluster is already initialized
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: kube_config

    - name: Gather proxy facts
      delegate_to: "{{ groups['k8proxy'][0] }}"
      delegate_facts: true
      ansible.builtin.gather_facts:
      when: not kube_config.stat.exists

    - name: Set Load Balancer to first node
      delegate_to: "{{ groups['k8proxy'][0] }}"
      ansible.builtin.template:
        src: haproxy.cfg.j2
        dest: /etc/haproxy/haproxy.cfg
        owner: root
        group: root
        mode: "0644"
      vars:
        kube_control_nodes:
          - "{{ groups['k8cdrs'][0] }}"
      when: not kube_config.stat.exists
      notify: Restart HAProxy

    - name: Slurp Proxy Certs
      delegate_to: "{{ groups['k8proxy'][0] }}"
      ansible.builtin.slurp:
        src: /etc/ssl/certs/kube_certs.crt
      register: proxy_cert
      changed_when: false

    - name: Slurp Proxy key
      delegate_to: "{{ groups['k8proxy'][0] }}"
      ansible.builtin.slurp:
        src: /etc/ssl/private/kube_certs.key
      register: proxy_key
      changed_when: false

    - name: Write Proxy Cert
      ansible.builtin.copy:
        content: "{{ proxy_cert.content | b64decode }}"
        dest: /etc/kubernetes/pki/front-proxy-ca.crt
        owner: kube
        group: docker
        mode: "0444"

    - name: Write Proxy key
      ansible.builtin.copy:
        content: "{{ proxy_key.content | b64decode }}"
        dest: /etc/kubernetes/pki/front-proxy-ca.key
        owner: kube
        group: docker
        mode: "0440"

    - name: Flush Handlers
      ansible.builtin.meta: flush_handlers

    - name: Ensure Containerd is started
      ansible.builtin.systemd:
        name: containerd
        state: started
        enabled: true

    - name: Check init_cluster
      ansible.builtin.command:
        cmd: |-
          kubeadm init
          --control-plane-endpoint "{{ groups["k8proxy"][0] }}:6443"
          --upload-certs
          --pod-network-cidr "{{ kube_network_real }}"
          --service-cidr "{{ kube_service_network_real }}"
          --feature-gates="PublicKeysECDSA=true"
        creates: /etc/kubernetes/admin.conf
      register: adm_output
      when: not kube_config.stat.exists
      changed_when: '"Your Kubernetes control-plane" " has initialized successfully!" in adm_output.stdout'

- name: Join Other Control Nodes
  hosts: k8cdrs[1:]
  strategy: linear
  tags:
    - control_init
  handlers:
    - name: Restart HAProxy
      delegate_to: "{{ groups['k8proxy'][0] }}"
      run_once: true # noqa: run-once
      become: true
      ansible.builtin.systemd:
        name: haproxy
        state: restarted
        enabled: true
        daemon_reload: true
    - name: Get certificate key
      delegate_to: "{{ groups['k8cdrs'][0] }}"
      run_once: true # noqa: run-once
      ansible.builtin.command:
        cmd: sudo kubeadm init phase upload-certs --upload-certs
      register: certificate_key
      changed_when: false
  tasks:
    - name: Determin if Node Needs Join the cluster
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: node_active
      changed_when: false

    - name: Check if we need the join key
      ansible.builtin.debug:
        msg: Check in progress
      changed_when: not node_active.stat.exists
      notify: Get certificate key

    - name: If we need to get the key lets get it
      ansible.builtin.meta: flush_handlers

    - name: Get Join Command
      delegate_to: "{{ groups['k8cdrs'][0] }}"
      become: true
      ansible.builtin.command:
        cmd: |-
          kubeadm token create
          --print-join-command
          --certificate-key "{{ certificate_key.stdout_lines[-1] }}"
          --ttl 15m
          --description
          "Ansible Node {{ inventory_hostname_short }} Join Command"
      register: join_command
      changed_when: true
      when: not node_active.stat.exists

    - name: Join Node to cluster
      become: true
      ansible.builtin.command:
        cmd: "{{ join_command.stdout }}"
        creates: /etc/kubernetes/admin.conf
      register: joined_to_cluster_test
      when: not node_active.stat.exists

    - name: Gather proxy facts
      delegate_to: "{{ groups['k8proxy'][0] }}"
      delegate_facts: true
      ansible.builtin.gather_facts:
      when: joined_to_cluster_test.changed # noqa: no-handler

    - name: Set Load Balancer to all nodes
      delegate_to: "{{ groups['k8proxy'][0] }}"
      become: true
      ansible.builtin.template:
        src: haproxy.cfg.j2
        dest: /etc/haproxy/haproxy.cfg
        owner: root
        group: root
        mode: "0644"
      vars:
        kube_control_nodes: "{{ groups['k8cdrs'] }}"
      notify: Restart HAProxy
      when: joined_to_cluster_test.changed # noqa: no-handler

- name: Join Worker Nodes
  hosts: k8wkrs
  vars:
    kube_service_network_real: "{{ kube_network | default('10.96.0.0/16') }}"
  tasks:
    - name: Check if node needs join
      ansible.builtin.stat:
        path: /etc/kubernetes/kubelet.conf
      register: node_needs_join
      changed_when: false

    - name: Get Join Command
      delegate_to: "{{ groups['k8cdrs'][0] }}"
      become: true
      ansible.builtin.command:
        cmd: |-
          kubeadm token create
          --print-join-command
          --ttl 15m
          --description
          'Ansible Node {{ inventory_hostname_short }} Join Command'
      register: node_join_command
      changed_when: not node_needs_join.stat.exists
      when: not node_needs_join.stat.exists

    - name: Join Node to cluster
      become: true
      ansible.builtin.command:
        cmd: "{{ node_join_command.stdout }}"
        creates: /etc/kubernetes/kubelet.conf
      when: not node_needs_join.stat.exists

    - name: Open UFW to service network
      become: true
      community.general.ufw:
        rule: allow
        to_ip: "{{ kube_service_network_real }}"
        from_ip: "{{ kube_service_network_real }}"

- name: Copy ADM Config
  hosts: k8cdrs[0]
  tasks:
    - name: Copy K8s Admin Config to /Share/k8s
      become: true
      ansible.builtin.fetch:
        remote_src: true
        src: /etc/kubernetes/admin.conf
        dest: /share/k8s/admin.conf
        mode: "0440"
        owner: Ansible
        group: Ansible
        flat: true

- name: Open Weave Ports
  hosts:
    - k8cdrs
    - k8wkrs
  tags:
    - pod_deploy
    - weave_cni
  become: true
  vars:
    kube_network_real: "{{ kube_network | default('10.32.0.0/12') }}"
  tasks:
    - name: Configure UFW 6783/TCP for weave CNI
      community.general.ufw:
        rule: allow
        port: 6783
        protocol: tcp
        comment: Allow 6783/TCP for weave CNI

    - name: Configure UFW services 6783:6784 for weave CNI
      community.general.ufw:
        rule: allow
        port: 6783:6784
        protocol: udp
        comment: Allow 6783:6784/UDP for weave CNI

    - name: Allow Kube Service Fabric
      community.general.ufw:
        rule: allow
        from_ip: "{{ kube_network_real }}"
        to_ip: "{{ kube_network_real }}"
        comment: Allow {{ kube_network_real }} for the KUBE Service Network

- name: Deploy Baseline Pods
  hosts: localhost
  tags:
    - pod_deploy
  vars:
    metallb_address_pool_real: "{{ metallb_address_pool | default('172.25.0.10/32') }}"
    traefik_address_real: "{{ traefik_address | default('172.25.0.10') }}"
    kube_network_real: "{{ kube_network | default('10.32.0.0/12') }}"
  tasks:
    - name: Install the Latest Weave Version
      tags:
        - weave_cni
      block:
        - name: Get Weave Latest Version Info
          ansible.builtin.uri:
            url: https://api.github.com/repos/weaveworks/weave/releases/latest
          register: weave_version

        - name: Get Weave file
          ansible.builtin.uri:
            url: >-
              https://github.com/weaveworks/weave/releases/download/{{- weave_version.json.tag_name -}}/weave-daemonset-k8s.yaml
            return_content: true
          register: weave_config_raw

        - name: Parase weave_config and Assemble new Weave Env
          ansible.builtin.set_fact:
            weave_config: "{{ weave_config_raw.content | from_yaml }}"
            weave_network_env:
              name: IPALLOC_RANGE
              value: "{{ kube_network_real }}"

        - name: Update weave_config
          ansible.builtin.set_fact:
            weave_config_updated: >-
              {%- for k8s_item in weave_config["items"] -%}
                {%- if k8s_item.kind == "DaemonSet" -%}
                  {%- for container in k8s_item.spec.template.spec.containers -%}
                    {{- container.__setitem__("env", []) if not container.env-}}
                    {{- container.env.append(weave_network_env) -}}
                  {%- endfor -%}
                  {%- for container in k8s_item.spec.template.spec.initContainers -%}
                    {{- container.__setitem__("env", []) if not container.env-}}
                    {{- container.env.append(weave_network_env) -}}
                  {%- endfor -%}
                {%- endif -%}
              {%- endfor -%}
              {{ weave_config }}

        - name: Setup Weave CNI networking
          kubernetes.core.k8s:
            kubeconfig: /share/k8s/admin.conf # noqa: jinja
            state: present
            definition: "{{ weave_config_updated }}"

    - name: Install the K8s Dashboard
      tags:
        - k8s_dashboard
      block:
        - name: Get Latest k8s Dashboard
          ansible.builtin.uri:
            url: https://api.github.com/repos/kubernetes/dashboard/releases?per_page=10
          register: dashboard_version_info
        - name: Compute version
          ansible.builtin.set_fact:
            dashboard_version: |-
              {%- set found_version = [false] -%}
              {%- for item in dashboard_version_info.json -%}
              {%- if not found_version[0] and not item.draft -%}
              {%- if not item.prerelease -%}
              {%- if "-alpha" not in item.name and "-beta" not in item.name -%}
              {{- item.name -}}
              {{- found_version.insert(0, true) -}}
              {%- endif -%}{%- endif -%}{%- endif -%}
              {%- endfor -%}
        - name: Deploy K8s Dashboard
          kubernetes.core.k8s:
            kubeconfig: /share/k8s/admin.conf # noqa: jinja
            state: present
            src: >
              https://raw.githubusercontent.com/kubernetes/dashboard/
              {{- dashboard_version -}}/aio/deploy/recommended.yaml

    - name: Install the MetalLB contoller
      tags:
        - metallb
      block:
        - name: Get Latest MetalLB version
          ansible.builtin.uri:
            url: https://api.github.com/repos/metallb/metallb/releases/latest
          register: metallb_version_info

        - name: Ensure Strict ARP is disabled
          block:
            - name: Get Cluster Current Config
              kubernetes.core.k8s_info:
                kubeconfig: /share/k8s/admin.conf
                kind: configmap
                namespace: kube-system
                name: kube-proxy
              register: k8s_kube_proxy_raw

            - name: Parse Config Data
              ansible.builtin.set_fact:
                k8s_kube_prox_data_parsed: "{{ k8s_kube_proxy_raw.resources[0].data['config.conf'] | replace('\"', '') | from_yaml }}"

            - name: Update Config Data
              ansible.builtin.set_fact:
                k8s_kube_prox_data: "{{ k8s_kube_prox_data_parsed | combine({'ipvs': {'strictARP': false}}, recursive=True) }}"

            - name: Ensure Strict ARP is disabled
              kubernetes.core.k8s:
                kubeconfig: /share/k8s/admin.conf
                kind: configmap
                namespace: kube-system
                name: kube-proxy
                state: present
                definition:
                  apiVersion: v1
                  kind: ConfigMap
                  metadata:
                    name: kube-proxy
                    namespace: kube-system
                  data:
                    config.conf: "{{ k8s_kube_prox_data | to_nice_yaml(width=80, indent=2) }}"

        - name: Deploy K8s MetalLB
          kubernetes.core.k8s:
            kubeconfig: /share/k8s/admin.conf # noqa: jinja
            state: present
            src: >-
              https://raw.githubusercontent.com/metallb/metallb/
              {{- metallb_version_info.json.tag_name -}}/config/{{- '' -}}
              manifests/metallb-native.yaml
          register: metal_deployed

        - name: Wait for metal to startup # noqa: no-handler
          when: metal_deployed.changed
          ansible.builtin.wait_for:
            timeout: 60

        - name: Install Pod Networking Addresses
          kubernetes.core.k8s:
            kubeconfig: /share/k8s/admin.conf
            state: present
            definition:
              apiVersion: metallb.io/v1beta1
              kind: IPAddressPool
              metadata:
                name: servernet-k8s-address-pool
                namespace: metallb-system
              spec:
                addresses: "{{ metallb_address_pool_real }}"
                autoAssign: true

        - name: Install Pod L2 config
          tags:
            - never
            - metal-l2_advertise
          kubernetes.core.k8s:
            kubeconfig: /share/k8s/admin.conf
            state: present
            api_version: metallb.io/v1beta1
            kind: L2Advertisement
            name: servernet-k8s-l2-advertisment
            namespace: metallb-system
            definition:
              spec:
                ipAddressPools:
                  - servernet-k8s-address-pool

        - name: Install Pod BGP config
          kubernetes.core.k8s:
            kubeconfig: /share/k8s/admin.conf
            state: present
            api_version: metallb.io/v1beta1
            kind: BGPAdvertisement
            name: servernet-k8s-bgp-advertisment
            namespace: metallb-system
            definition:
              spec:
                ipAddressPools:
                  - servernet-k8s-address-pool

    - name: Install the Traefik Ingest controller
      tags:
        - traefik_ingest
      block:
        - name: Install the Traefik Helm repo
          kubernetes.core.helm_repository:
            kubeconfig: /share/k8s/admin.conf
            repo_name: traefik
            repo_state: present
            repo_url: https://traefik.github.io/charts
        - name: Install the Traefik Ingest controller
          kubernetes.core.helm:
            kubeconfig: /share/k8s/admin.conf
            chart_ref: traefik/traefik
            name: traefik
            state: present
            release_namespace: traefik
            create_namespace: true
        - name: Set Traefik LB IP
          kubernetes.core.k8s:
            kubeconfig: /share/k8s/admin.conf
            state: patched
            kind: Service
            namespace: traefik
            name: traefik
            definition:
              metadata:
                annotations:
                  metallb.universe.tf/loadBalancerIPs: "{{ traefik_address_real }}"

- name: Open Traefik Ports on Worker Nodes
  hosts: k8wkrs
  tags:
    - pod_deploy
    - traefik_ingest
  vars:
    traefik_address_real: "{{ traefik_address | default('172.25.0.10') }}"
  become: true
  tasks:
    - name: Expose Traefik ports
      community.general.ufw:
        rule: allow
        name: "{{ item }}"
        to_ip: "{{ traefik_address_real }}"
        comment: Allow {{ item }} for Traefik
        delete: true
      with_items:
        - http
        - https
